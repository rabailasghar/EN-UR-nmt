
Based on your training command, you can add the --save-interval-updates argument to specify how often to save checkpoints. For example, if you want to save a checkpoint every 500 updates, you can add --save-interval-updates 500 to your training command:


CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 fairseq-train data-bin/wmt14_en_de \
--arch transformer_wmt_en_de  --share-all-embeddings \
--optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0  \
--lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 \
--warmup-updates 8000 --lr 0.0007 --stop-min-lr 1e-09 \
--criterion label_smoothed_mse_with_alignment --load-alignments \
--alignment-lambda 0.5 --label-smoothing 0.1 --weight-decay 0.0 \    
--max-tokens  4096  --save-dir ./checkpoints/wmt14_en_de \
--max-update 288000  --seed 3435 --distributed-world-size 8 \
--eval-bleu  --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}'  \
--eval-bleu-detok moses     --eval-bleu-remove-bpe \
--best-checkpoint-metric bleu --maximize-best-checkpoint-metric \
--eval-bleu-print-samples --ddp-backend=no_c10d \
--save-interval-updates 500

This will save a checkpoint every 500 updates, which will allow you to resume training from the last saved checkpoint if your session gets terminated. You can adjust the save-interval-updates value as per your requirement.

To resume training from a saved checkpoint, you can use the --restore-file argument to specify the path to the checkpoint file you want to resume from.

For example, let's say you have saved a checkpoint at checkpoints/wmt14_en_de/checkpoint_best.pt. To resume training from this checkpoint, you can modify your command as follows:

CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 fairseq-train data-bin/wmt14_en_de \
--arch transformer_wmt_en_de  --share-all-embeddings \
--optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0  \
--lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 \
--warmup-updates 8000 --lr 0.0007 --stop-min-lr 1e-09 \
--criterion label_smoothed_mse_with_alignment --load-alignments \
--alignment-lambda 0.5 --label-smoothing 0.1 --weight-decay 0.0 \    
--max-tokens  4096  --save-dir ./checkpoints/wmt14_en_de \
--max-update 288000  --seed 3435 --distributed-world-size 8 \
--eval-bleu  --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}'  \
--eval-bleu-detok moses     --eval-bleu-remove-bpe \
--best-checkpoint-metric bleu --maximize-best-checkpoint-metric \
--eval-bleu-print-samples --ddp-backend=no_c10d \
--restore-file checkpoints/wmt14_en_de/checkpoint_best.pt


Note that the --restore-file argument is added to the end of the command. This will load the checkpoint file and continue training from where it left off.

